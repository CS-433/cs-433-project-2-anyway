{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from math import sqrt as sqrt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.autograd import Function\n",
    "import torch.nn.init as init\n",
    "from ssd_project.model import ssd\n",
    "from ssd_project.functions.detection import *\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#color detection of red and green color in image\n",
    "#necessary libraries \n",
    "import matplotlib.patches as patches\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import os.path\n",
    "from cv2 import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter with building detection model (breif select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:/Users/Xiaorang/Desktop/Project/SSD_FacadeParsing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(\"./saved_models/Best_model_ssd300.pth.tar\")\n",
    "model = ssd.build_ssd(num_classes = 4)\n",
    "model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "\n",
    "epochs_trained = best_model[\"epoch\"]\n",
    "best_avg_loss = best_model[\"loss\"]\n",
    "t_loss_bvals = best_model[\"training_losses_batch_values\"]\n",
    "t_loss_bavgs = best_model[\"training_losses_batch_avgs\"]\n",
    "v_loss_bvals = best_model[\"validation_losses_batch_values\"]\n",
    "v_loss_bavgs = best_model[\"validation_losses_batch_avgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3953616943359375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_num_img(img_path):\n",
    "    arr = img_path.split(\"/\")\n",
    "    name = arr[len(arr)-1]\n",
    "    arr = name.split(\"_\")\n",
    "    num = arr[len(arr)-1].split(\".\")[0]\n",
    "    \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(position_window,position_building):\n",
    "    \"\"\"\n",
    "    If the position of window lay outside the building reture False, otherwise True\n",
    "    \"\"\"\n",
    "    if((position_window[0]>position_building[0])&(position_window[2]<position_building[2])&(position_window[3]<position_building[3])&(position_window[1]>position_building[1])):\n",
    "        return True #in the building\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiaorang\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py:144: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:25.)\n",
      "  bboxes_nms = class_decoded_locs[1 - suppress]\n",
      "C:\\Users\\Xiaorang\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py:146: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ..\\aten\\src\\ATen/native/IndexingUtils.h:25.)\n",
      "  scores_nms = class_scores[1 - suppress]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n",
      "The window outside the building\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6eab4addd827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mpred_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_overlap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mannotated_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw_detected_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_num_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mpredict_objects\u001b[1;34m(model, path_img, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;31m# get best objects and suppress redudant objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     det_boxes, det_labels, det_scores = detect_objects(predicted_locs, predicted_scores, model.priors_cxcy, min_score,\n\u001b[0m\u001b[0;32m    196\u001b[0m                                                                    max_overlap, top_k)\n\u001b[0;32m    197\u001b[0m     \u001b[1;31m# Move detections to the CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mdetect_objects\u001b[1;34m(predicted_locs, predicted_scores, priors_cxcy, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m#Apply Non-Maximum Supression, if multiples priors overlap significantly(max_overlap as threshold)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m#We remove those redudant predictions by supressing all but one with the maximum score.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             bboxes_nms, labels_nms, scores_nms = nms(decoded_locs, class_scores, score_above_min_score,\n\u001b[0m\u001b[0;32m     67\u001b[0m                                         num_above_min_score, max_overlap, cls)\n\u001b[0;32m     68\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbboxes_nms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mnms\u001b[1;34m(decoded_locs, class_scores, score_above_min_score, num_above_min_score, max_overlap, cls)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[1;31m#Apply jaccard_overlap to all boxes between each other\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0moverlap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjaccard_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_decoded_locs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_decoded_locs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0msuppress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_above_min_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\utils\\utils.py\u001b[0m in \u001b[0;36mjaccard_overlap\u001b[1;34m(set_a, set_b)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \"\"\"\n\u001b[1;32m--> 123\u001b[1;33m     \u001b[0mintersection_seta_setb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[0marea_set_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mset_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\utils\\utils.py\u001b[0m in \u001b[0;36mintersection\u001b[1;34m(box_a, box_b)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0minter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_xy\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_xy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0minter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjaccard_overlap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_save_good = \"./data/prediction_good/\"\n",
    "path_to_save_bad = \"./data/prediction_bad/\"\n",
    "file_good = \"./data/prediction_good/ratios_good.csv\"\n",
    "file_bad = \"./data/prediction_bad/ratios_bad.csv\"\n",
    "imgs = glob.glob(\"./data/buildings/*\")\n",
    "imgs.sort()\n",
    "if os.path.exists(file_good):\n",
    "    locFile_good = open(file_good,\"a\")\n",
    "else:\n",
    "    locFile_good = open(file_good,\"w+\")\n",
    "    locFile_good.write(\"Names, Ratios\\n\")\n",
    "if os.path.exists(file_bad):\n",
    "    locFile_bad = open(file_bad,\"a\")\n",
    "else:\n",
    "    locFile_bad = open(file_bad,\"w+\")\n",
    "    locFile_bad.write(\"Names, Ratios\\n\")\n",
    "for i, img in enumerate(imgs):\n",
    "    \n",
    "    pred_img, bboxes, labels, scores = predict_objects(model, img, min_score=0.2, max_overlap = 0.01, top_k=200)\n",
    "    annotated_img = FT.to_pil_image(draw_detected_objects(img, bboxes, labels, scores))\n",
    "    num = return_num_img(img)\n",
    "    name = \"annotated_img_\" + num + \".png\"\n",
    "    path_img_good = path_to_save_good + name\n",
    "    path_img_bad = path_to_save_bad + name\n",
    "\n",
    "    # Windows Ratio calculation \n",
    "    building_area = (bboxes[0][2] - bboxes[0][0])*(bboxes[0][3] - bboxes[0][1])\n",
    "    position_building = [bboxes[0][0],bboxes[0][1],bboxes[0][2],bboxes[0][3]]\n",
    "    windows_area = 0\n",
    "    flag = True # assume it in the building\n",
    "    for j in range(1,len(bboxes)):\n",
    "        windows_area = windows_area + (bboxes[j][2] - bboxes[j][0])*(bboxes[j][3] - bboxes[j][1])\n",
    "        position_window = [bboxes[j][0],bboxes[j][1],bboxes[j][2],bboxes[j][3]]\n",
    "        flag = flag&compare(position_window,position_building)\n",
    "    if(flag == False):\n",
    "        #print('The window outside the building')\n",
    "    ratio = windows_area/building_area\n",
    "    if ((ratio>0.025)&(ratio<0.85)&flag):\n",
    "    #if ((ratio>0.025)&(ratio<0.85)): \n",
    "        pred_img.save(path_img_good, \"PNG\")\n",
    "        locFile_good.write(name+\",\"+str(float(ratio.detach().numpy()))+'\\n')\n",
    "    else:\n",
    "        pred_img.save(path_img_bad, \"PNG\")\n",
    "        locFile_bad.write(name+\",\"+str(float(ratio.detach().numpy()))+'\\n')\n",
    "locFile_bad.close()\n",
    "locFile_good.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter with green ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_area(image):\n",
    "    green = np.uint8([[[0, 255, 0]]])  #green color\n",
    "    hsvGreen = cv2.cvtColor(green, cv2.COLOR_BGR2HSV) #hsv value of green color \n",
    "    lowerLimit = hsvGreen[0][0][0] - 30, 40, 40  # range of green color lower limit and upper limit\n",
    "    upperLimit = hsvGreen[0][0][0] + 10, 255, 255\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert the image into hsv\n",
    "    lg = np.array(lowerLimit) #range of green color\n",
    "    ug = np.array(upperLimit)\n",
    "    #print(lg,ug)\n",
    "    green_mask = cv2.inRange(hsv, lg, ug) #green masked image    \n",
    "    contours, hiera = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    area = 0\n",
    "    for i in contours:\n",
    "        area += cv2.contourArea(i)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_numbers_from_filename(filename):\n",
    "    return re.search(r'\\d+', filename).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "save = []\n",
    "names = []\n",
    "reasons = []\n",
    "imgPaths = sorted(list(paths.list_images(\"./data/buildings\")))\n",
    "path_to_save_bad = \"./data/detect_green_removed/\"\n",
    "path_to_save_good = \"./data/detect_green_retained/\"\n",
    "for imgPath in imgPaths:\n",
    "    number = get_numbers_from_filename(imgPath)\n",
    "    image = cv2.imread(imgPath) #load image \n",
    "    area_green = green_area(image)\n",
    "    total_area = image.shape[0] * image.shape[1]\n",
    "    ratio_green = area_green/ total_area\n",
    "    #print(ratio_green)\n",
    "    saved = 0\n",
    "    # Store the images with green_detected\n",
    "    if ratio_green > 0.25:\n",
    "        #num = return_num_img(imgPath)\n",
    "        name = \"img_\" + number + \".jpg\"\n",
    "        path_img_bad = path_to_save_bad + name\n",
    "        saved = 0\n",
    "        reason = 'too many greens'\n",
    "        cv2.imwrite(path_img_bad, image)\n",
    "    else:\n",
    "        #num = return_num_img(imgPath)\n",
    "        name = \"img_\" + number + \".jpg\"\n",
    "        path_img_good = path_to_save_good + name\n",
    "        saved = 1\n",
    "        reason = 'None'\n",
    "        cv2.imwrite(path_img_good, image)\n",
    "    names.append(name)\n",
    "    save.append(saved)\n",
    "    reasons.append(reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3055"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = pd.DataFrame(names,columns =['name'])\n",
    "df_save = pd.DataFrame(save)\n",
    "#df_names = pd.DataFrame(names)\n",
    "df_reason = pd.DataFrame(reasons)\n",
    "df_green['save'] = df_save\n",
    "#df_class['names'] = df_names\n",
    "df_green['reason'] = df_reason\n",
    "df_green.to_csv('df_green.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter cars with original SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Xiaorang/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in C:\\Users\\Xiaorang/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD300(\n",
       "  (feature_extractor): ResNet(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (additional_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "ssd_model.to('cuda')\n",
    "ssd_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "imgPath = sorted(list(paths.list_images(\"./data/detect_green_retained\")))\n",
    "path_to_save_good = \"./data/detect_car_retained/\"\n",
    "path_to_save_bad = \"./data/detect_car_removed/\"\n",
    "save = []\n",
    "names = []\n",
    "while(imgPath):\n",
    "    # Grab data in a group of three\n",
    "    if len(imgPath)<3:\n",
    "        uris = []\n",
    "        for i in range(len(imgPath)):\n",
    "            uris.append(imgPath.pop(0))\n",
    "    else:\n",
    "        uris = imgPath[0:3]\n",
    "        imgPath = imgPath[3:]\n",
    "    \n",
    "    # Detect car\n",
    "    try:\n",
    "        images = [cv2.imread(k) for k in uris]\n",
    "        inputs = [utils.prepare_input(uri) for uri in uris]\n",
    "        tensor = utils.prepare_tensor(inputs, precision == 'fp16')\n",
    "        detections_batch = ssd_model(tensor)\n",
    "        results_per_input = utils.decode_results(detections_batch)\n",
    "        best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
    "        classes_to_labels = utils.get_coco_object_dictionary()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for image_idx in range(len(best_results_per_input)):\n",
    "        # Show original, denormalized image...\n",
    "        #image = inputs[image_idx]\n",
    "        image = images[image_idx]\n",
    "        # ...with detections\n",
    "        bboxes, classes, confidences = results_per_input[image_idx]\n",
    "        area = 0\n",
    "        confidence = 0\n",
    "        if(3 in classes):\n",
    "            area = 0\n",
    "            for idx in np.where(classes==3)[0]:\n",
    "                idx =int(idx)\n",
    "                left, bot, right, top = bboxes[idx]\n",
    "                area = area + (right - left)*(top - bot)\n",
    "                confidence = max(confidence,confidences[idx])\n",
    "#             print(area)\n",
    "#             print(confidence)\n",
    "        if (area>0.12) & (confidence>0.7):\n",
    "            #image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            number = get_numbers_from_filename(uris[image_idx])\n",
    "            name = \"img_\" + number + \".jpg\"\n",
    "            saved = 0\n",
    "            path_img_bad = path_to_save_bad + name\n",
    "            cv2.imwrite(path_img_bad, image)\n",
    "        else:\n",
    "            #image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            number = get_numbers_from_filename(uris[image_idx])\n",
    "            name = \"img_\" + number + \".jpg\"\n",
    "            saved = 1\n",
    "            path_img_good = path_to_save_good + name\n",
    "            cv2.imwrite(path_img_good, image)\n",
    "        names.append(name)\n",
    "        save.append(saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_car = pd.DataFrame(names,columns =['name'])\n",
    "df_save = pd.DataFrame(save)\n",
    "df_car['save'] = df_save\n",
    "df_car.to_csv('df_car.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the building detection model on filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-da90b248a30b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpred_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_overlap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mannotated_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw_detected_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_numbers_from_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mpredict_objects\u001b[1;34m(model, path_img, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;31m# get best objects and suppress redudant objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     det_boxes, det_labels, det_scores = detect_objects(predicted_locs, predicted_scores, model.priors_cxcy, min_score,\n\u001b[0m\u001b[0;32m    196\u001b[0m                                                                    max_overlap, top_k)\n\u001b[0;32m    197\u001b[0m     \u001b[1;31m# Move detections to the CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mdetect_objects\u001b[1;34m(predicted_locs, predicted_scores, priors_cxcy, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mclass_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconf_scores_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# (8732)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mscore_above_min_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mnum_above_min_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_above_min_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_above_min_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# root_path = r'C:/Users/Xiaorang/Desktop/Project/src/dataset'\n",
    "# resultFolder = root_path + '/result/'\n",
    "\n",
    "# imgs = glob.glob(resultFolder + '/*.png')\n",
    "imgs = glob.glob(\"./data/detect_car_retained/*\")\n",
    "imgs.sort()\n",
    "path_to_save = \"./data/result/\"\n",
    "for i, img in enumerate(imgs):\n",
    "    \n",
    "    pred_img, bboxes, labels, scores = predict_objects(model, img, min_score=0.2, max_overlap = 0.01, top_k=200)\n",
    "    annotated_img = FT.to_pil_image(draw_detected_objects(img, bboxes, labels, scores))\n",
    "    number = get_numbers_from_filename(img)\n",
    "    \n",
    "    path_img = path_to_save + \"annotated_img_\" + number + \".png\"\n",
    "    \n",
    "    annotated_img.save(path_img, \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
