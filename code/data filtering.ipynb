{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from math import sqrt as sqrt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from torch.autograd import Function\n",
    "import torch.nn.init as init\n",
    "from ssd_project.model import ssd\n",
    "from ssd_project.functions.detection import *\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "#color detection of red and green color in image\n",
    "#necessary libraries \n",
    "import matplotlib.patches as patches\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import os.path\n",
    "from cv2 import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter with building detection model (breif select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_directory=\"./SSD_FacadeParsing/\"\n",
    "path_to_save_good=\"./data/prediction_good/\"\n",
    "path_to_save_bad=\"./data/prediction_bad/\"\n",
    "file_good=\"./data/prediction_good/ratios_good.csv\"\n",
    "file_bad=\"./data/prediction_bad/ratios_bad.csv\"\n",
    "data_directory=\"./data/original_images/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(working_directory)  # change the directory to your working space\n",
    "imgs = glob.glob(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/original_images\\\\img_resized_000.png',\n",
       " './data/original_images\\\\img_resized_001.png',\n",
       " './data/original_images\\\\img_resized_002.png',\n",
       " './data/original_images\\\\img_resized_003.png',\n",
       " './data/original_images\\\\img_resized_004.png',\n",
       " './data/original_images\\\\img_resized_005.png',\n",
       " './data/original_images\\\\img_resized_006.png',\n",
       " './data/original_images\\\\img_resized_007.png',\n",
       " './data/original_images\\\\img_resized_008.png',\n",
       " './data/original_images\\\\img_resized_009.png']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh! you are trying to use CPU, are you sure??\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    best_model = torch.load(\"./saved_models/Best_model_ssd300.pth.tar\",map_location=torch.device('cpu'))\n",
    "    model = ssd.build_ssd(num_classes = 4)\n",
    "    model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "    device = \"cpu\"\n",
    "    model = model.to(device)\n",
    "    print(\"Oh! you are trying to use CPU, are you sure??\")\n",
    "else:\n",
    "    best_model = torch.load(\"./saved_models/Best_model_ssd300.pth.tar\")\n",
    "    model = ssd.build_ssd(num_classes = 4)\n",
    "    model.load_state_dict(best_model[\"model_state_dict\"])\n",
    "    device = \"cuda\"\n",
    "    model = model.to(device)\n",
    "\n",
    "epochs_trained = best_model[\"epoch\"]\n",
    "best_avg_loss = best_model[\"loss\"]\n",
    "t_loss_bvals = best_model[\"training_losses_batch_values\"]\n",
    "t_loss_bavgs = best_model[\"training_losses_batch_avgs\"]\n",
    "v_loss_bvals = best_model[\"validation_losses_batch_values\"]\n",
    "v_loss_bavgs = best_model[\"validation_losses_batch_avgs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_num_img(img_path):\n",
    "    arr = img_path.split(\"/\")\n",
    "    name = arr[len(arr)-1]\n",
    "    arr = name.split(\"_\")\n",
    "    num = arr[len(arr)-1].split(\".\")[0]\n",
    "    \n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(position_window,position_building):\n",
    "    \"\"\"\n",
    "    If the position of window lay outside the building reture False, otherwise True\n",
    "    \"\"\"\n",
    "    if((position_window[0]>position_building[0])&(position_window[2]<position_building[2])&(position_window[3]<position_building[3])&(position_window[1]>position_building[1])):\n",
    "        return True #in the building\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/original_images\\\\img_resized_000.png',\n",
       " './data/original_images\\\\img_resized_001.png',\n",
       " './data/original_images\\\\img_resized_002.png',\n",
       " './data/original_images\\\\img_resized_003.png',\n",
       " './data/original_images\\\\img_resized_004.png',\n",
       " './data/original_images\\\\img_resized_005.png',\n",
       " './data/original_images\\\\img_resized_006.png',\n",
       " './data/original_images\\\\img_resized_007.png',\n",
       " './data/original_images\\\\img_resized_008.png',\n",
       " './data/original_images\\\\img_resized_009.png']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0,img: ./data/original_images\\img_resized_000.png\n",
      "The window outside the building\n",
      "i: 1,img: ./data/original_images\\img_resized_001.png\n",
      "The window outside the building\n",
      "i: 2,img: ./data/original_images\\img_resized_002.png\n",
      "i: 3,img: ./data/original_images\\img_resized_003.png\n",
      "i: 4,img: ./data/original_images\\img_resized_004.png\n",
      "The window outside the building\n",
      "i: 5,img: ./data/original_images\\img_resized_005.png\n",
      "The window outside the building\n",
      "i: 6,img: ./data/original_images\\img_resized_006.png\n",
      "i: 7,img: ./data/original_images\\img_resized_007.png\n",
      "The window outside the building\n",
      "i: 8,img: ./data/original_images\\img_resized_008.png\n",
      "i: 9,img: ./data/original_images\\img_resized_009.png\n",
      "The window outside the building\n"
     ]
    }
   ],
   "source": [
    "path_to_save_good = \"./data/prediction_good/\"\n",
    "path_to_save_bad = \"./data/prediction_bad/\"\n",
    "file_good = \"./data/prediction_good/ratios_good.csv\"\n",
    "file_bad = \"./data/prediction_bad/ratios_bad.csv\"\n",
    "imgs = glob.glob(\"./data/original_images/*\")\n",
    "imgs.sort()\n",
    "if os.path.exists(file_good):\n",
    "    locFile_good = open(file_good,\"a\")\n",
    "else:\n",
    "    locFile_good = open(file_good,\"w+\")\n",
    "    locFile_good.write(\"Names, Ratios\\n\")\n",
    "if os.path.exists(file_bad):\n",
    "    locFile_bad = open(file_bad,\"a\")\n",
    "else:\n",
    "    locFile_bad = open(file_bad,\"w+\")\n",
    "    locFile_bad.write(\"Names, Ratios\\n\")\n",
    "for i, img in enumerate(imgs):\n",
    "    print(\"i: {},img: {}\".format(i,img))\n",
    "    pred_img, bboxes, labels, scores = predict_objects(model, img, min_score=0.2, max_overlap = 0.01, top_k=200)\n",
    "    annotated_img = FT.to_pil_image(draw_detected_objects(img, bboxes, labels, scores))\n",
    "    num = return_num_img(img)\n",
    "    name = \"annotated_img_\" + num + \".png\"\n",
    "    path_img_good = path_to_save_good + name\n",
    "    path_img_bad = path_to_save_bad + name\n",
    "\n",
    "    # Windows Ratio calculation \n",
    "    building_area = (bboxes[0][2] - bboxes[0][0])*(bboxes[0][3] - bboxes[0][1])\n",
    "    position_building = [bboxes[0][0],bboxes[0][1],bboxes[0][2],bboxes[0][3]]\n",
    "    windows_area = 0\n",
    "    flag = True # assume it in the building\n",
    "    for j in range(1,len(bboxes)):\n",
    "        windows_area = windows_area + (bboxes[j][2] - bboxes[j][0])*(bboxes[j][3] - bboxes[j][1])\n",
    "        position_window = [bboxes[j][0],bboxes[j][1],bboxes[j][2],bboxes[j][3]]\n",
    "        flag = flag&compare(position_window,position_building)\n",
    "    if(flag == False):\n",
    "        print('The window outside the building')\n",
    "    ratio = windows_area/building_area\n",
    "    if ((ratio>0.025)&(ratio<0.85)&flag):\n",
    "    #if ((ratio>0.025)&(ratio<0.85)): \n",
    "        pred_img.save(path_img_good, \"PNG\")\n",
    "        locFile_good.write(name+\",\"+str(float(ratio.detach().numpy()))+'\\n')\n",
    "    else:\n",
    "        pred_img.save(path_img_bad, \"PNG\")\n",
    "        locFile_bad.write(name+\",\"+str(float(ratio.detach().numpy()))+'\\n')\n",
    "locFile_bad.close()\n",
    "locFile_good.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter with green ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def green_area(image):\n",
    "    green = np.uint8([[[0, 255, 0]]])  #green color\n",
    "    hsvGreen = cv2.cvtColor(green, cv2.COLOR_BGR2HSV) #hsv value of green color \n",
    "    lowerLimit = hsvGreen[0][0][0] - 30, 40, 40  # range of green color lower limit and upper limit\n",
    "    upperLimit = hsvGreen[0][0][0] + 10, 255, 255\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #convert the image into hsv\n",
    "    lg = np.array(lowerLimit) #range of green color\n",
    "    ug = np.array(upperLimit)\n",
    "    #print(lg,ug)\n",
    "    green_mask = cv2.inRange(hsv, lg, ug) #green masked image    \n",
    "    contours, hiera = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    area = 0\n",
    "    for i in contours:\n",
    "        area += cv2.contourArea(i)\n",
    "    return area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_numbers_from_filename(filename):\n",
    "    return re.search(r'\\d+', filename).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/original_images\\img_resized_000.png\n",
      "0.008522222222222223\n",
      "./data/original_images\\img_resized_001.png\n",
      "0.05890555555555556\n",
      "./data/original_images\\img_resized_002.png\n",
      "0.04884444444444445\n",
      "./data/original_images\\img_resized_003.png\n",
      "0.003011111111111111\n",
      "./data/original_images\\img_resized_004.png\n",
      "0.02118888888888889\n",
      "./data/original_images\\img_resized_005.png\n",
      "0.0017722222222222221\n",
      "./data/original_images\\img_resized_006.png\n",
      "0.010138888888888888\n",
      "./data/original_images\\img_resized_007.png\n",
      "0.2179888888888889\n",
      "./data/original_images\\img_resized_008.png\n",
      "0.1002611111111111\n",
      "./data/original_images\\img_resized_009.png\n",
      "0.1973888888888889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "save = []\n",
    "names = []\n",
    "reasons = []\n",
    "imgPaths = sorted(list(paths.list_images(\"./data/original_images\")))\n",
    "path_to_save_bad = \"./data/detect_green_removed/\"\n",
    "path_to_save_good = \"./data/detect_green_retained/\"\n",
    "for imgPath in imgPaths:\n",
    "    print(imgPath)\n",
    "    number = get_numbers_from_filename(imgPath)\n",
    "    image = cv2.imread(imgPath) #load image \n",
    "    area_green = green_area(image)\n",
    "    total_area = image.shape[0] * image.shape[1]\n",
    "    ratio_green = area_green/ total_area\n",
    "    print(ratio_green)\n",
    "    saved = 0\n",
    "    # Store the images with green_detected\n",
    "    if ratio_green > 0.25:\n",
    "        #num = return_num_img(imgPath)\n",
    "        name = \"img_\" + number + \".jpg\"\n",
    "        path_img_bad = path_to_save_bad + name\n",
    "        saved = 0\n",
    "        reason = 'too many greens'\n",
    "        cv2.imwrite(path_img_bad, image)\n",
    "    else:\n",
    "        #num = return_num_img(imgPath)\n",
    "        name = \"img_\" + number + \".jpg\"\n",
    "        path_img_good = path_to_save_good + name\n",
    "        saved = 1\n",
    "        reason = 'None'\n",
    "        cv2.imwrite(path_img_good, image)\n",
    "    names.append(name)\n",
    "    save.append(saved)\n",
    "    reasons.append(reason)\n",
    "    # Create an .csv file to store all generated data, and recorde the index of saved or deleted image\n",
    "    df_green = pd.DataFrame(names,columns =['name'])\n",
    "    df_save = pd.DataFrame(save)\n",
    "    #df_names = pd.DataFrame(names)\n",
    "    df_reason = pd.DataFrame(reasons)\n",
    "    df_green['save'] = df_save\n",
    "    #df_class['names'] = df_names\n",
    "    df_green['reason'] = df_reason\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None',\n",
       " 'None']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an .csv file to store all generated data, and recorde the index of saved or deleted image\n",
    "df_green = pd.DataFrame(names,columns =['name'])\n",
    "df_save = pd.DataFrame(save)\n",
    "#df_names = pd.DataFrame(names)\n",
    "df_reason = pd.DataFrame(reasons)\n",
    "df_green['save'] = df_save\n",
    "#df_class['names'] = df_names\n",
    "df_green['reason'] = df_reason\n",
    "df_green.to_csv('df_green.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filter cars with original SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Xiaorang/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "Using cache found in C:\\Users\\Xiaorang/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SSD300(\n",
       "  (feature_extractor): ResNet(\n",
       "    (feature_extractor): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (additional_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 'fp32'\n",
    "ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)\n",
    "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n",
    "ssd_model.to('cuda')\n",
    "ssd_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import cv2\n",
    "imgPath = sorted(list(paths.list_images(\"./data/detect_green_retained\")))\n",
    "path_to_save_good = \"./data/detect_car_retained/\"\n",
    "path_to_save_bad = \"./data/detect_car_removed/\"\n",
    "save = []\n",
    "names = []\n",
    "while(imgPath):\n",
    "    # Grab data in a group of three\n",
    "    if len(imgPath)<3:\n",
    "        uris = []\n",
    "        for i in range(len(imgPath)):\n",
    "            uris.append(imgPath.pop(0))\n",
    "    else:\n",
    "        uris = imgPath[0:3]\n",
    "        imgPath = imgPath[3:]\n",
    "    \n",
    "    # Detect car\n",
    "    try:\n",
    "        images = [cv2.imread(k) for k in uris]\n",
    "        inputs = [utils.prepare_input(uri) for uri in uris]\n",
    "        tensor = utils.prepare_tensor(inputs, precision == 'fp16')\n",
    "        detections_batch = ssd_model(tensor)\n",
    "        results_per_input = utils.decode_results(detections_batch)\n",
    "        best_results_per_input = [utils.pick_best(results, 0.40) for results in results_per_input]\n",
    "        classes_to_labels = utils.get_coco_object_dictionary()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for image_idx in range(len(best_results_per_input)):\n",
    "        # Show original, denormalized image...\n",
    "        #image = inputs[image_idx]\n",
    "        image = images[image_idx]\n",
    "        # ...with detections\n",
    "        bboxes, classes, confidences = results_per_input[image_idx]\n",
    "        area = 0\n",
    "        confidence = 0\n",
    "        if(3 in classes):\n",
    "            area = 0\n",
    "            for idx in np.where(classes==3)[0]:\n",
    "                idx =int(idx)\n",
    "                left, bot, right, top = bboxes[idx]\n",
    "                area = area + (right - left)*(top - bot)\n",
    "                confidence = max(confidence,confidences[idx])\n",
    "#             print(area)\n",
    "#             print(confidence)\n",
    "        if (area>0.12) & (confidence>0.7):\n",
    "            #image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            number = get_numbers_from_filename(uris[image_idx])\n",
    "            name = \"img_\" + number + \".jpg\"\n",
    "            saved = 0\n",
    "            path_img_bad = path_to_save_bad + name\n",
    "            cv2.imwrite(path_img_bad, image)\n",
    "        else:\n",
    "            #image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "            number = get_numbers_from_filename(uris[image_idx])\n",
    "            name = \"img_\" + number + \".jpg\"\n",
    "            saved = 1\n",
    "            path_img_good = path_to_save_good + name\n",
    "            cv2.imwrite(path_img_good, image)\n",
    "        names.append(name)\n",
    "        save.append(saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_car = pd.DataFrame(names,columns =['name'])\n",
    "df_save = pd.DataFrame(save)\n",
    "df_car['save'] = df_save\n",
    "df_car.to_csv('df_car.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the building detection model on filtered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-da90b248a30b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpred_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_overlap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mannotated_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdraw_detected_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_numbers_from_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mpredict_objects\u001b[1;34m(model, path_img, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;31m# get best objects and suppress redudant objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m     det_boxes, det_labels, det_scores = detect_objects(predicted_locs, predicted_scores, model.priors_cxcy, min_score,\n\u001b[0m\u001b[0;32m    196\u001b[0m                                                                    max_overlap, top_k)\n\u001b[0;32m    197\u001b[0m     \u001b[1;31m# Move detections to the CPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ssd_project\\functions\\detection.py\u001b[0m in \u001b[0;36mdetect_objects\u001b[1;34m(predicted_locs, predicted_scores, priors_cxcy, min_score, max_overlap, top_k)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mclass_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconf_scores_img\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# (8732)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[0mscore_above_min_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mnum_above_min_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore_above_min_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_above_min_score\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# root_path = r'C:/Users/Xiaorang/Desktop/Project/src/dataset'\n",
    "# resultFolder = root_path + '/result/'\n",
    "\n",
    "# imgs = glob.glob(resultFolder + '/*.png')\n",
    "imgs = glob.glob(\"./data/detect_car_retained/*\")\n",
    "imgs.sort()\n",
    "path_to_save = \"./data/result/\"\n",
    "for i, img in enumerate(imgs):\n",
    "    \n",
    "    pred_img, bboxes, labels, scores = predict_objects(model, img, min_score=0.2, max_overlap = 0.01, top_k=200)\n",
    "    annotated_img = FT.to_pil_image(draw_detected_objects(img, bboxes, labels, scores))\n",
    "    number = get_numbers_from_filename(img)\n",
    "    \n",
    "    path_img = path_to_save + \"annotated_img_\" + number + \".png\"\n",
    "    \n",
    "    annotated_img.save(path_img, \"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
